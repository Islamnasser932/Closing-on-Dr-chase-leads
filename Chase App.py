import streamlit as st
import pandas as pd
import plotly.express as px
from plotly.subplots import make_subplots
import plotly.graph_objects as go
from streamlit_extras.metric_cards import style_metric_cards
import numpy as np # <--- Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ø³Ø·Ø± Ø§Ù„Ø°ÙŠ ÙŠØ¶Ù…Ù† ØªØ¹Ø±ÙŠÙ 'np'

# ================== 0ï¸âƒ£ CONFIGURATION ==================
st.set_page_config(
Â  Â  page_title="Closing Report Dashboard",
Â  Â  page_icon="ğŸ“Š",
Â  Â  layout="wide",
Â  Â  initial_sidebar_state="expanded"
)

# ================== 1ï¸âƒ£ DATA LOADING (with appropriate encoding) ==================
@st.cache_data
def load_and_merge_data():
Â  Â  try:
Â  Â  Â  Â  # Load Dr_Chase_Leads (using latin-1 as determined previously)
Â  Â  Â  Â  dr = pd.read_csv("Dr_Chase_Leads.csv", encoding='latin-1', low_memory=False)
Â  Â  Â  Â  # Load O_Plan_Leads (using latin-1 as determined previously)
Â  Â  Â  Â  oplan = pd.read_csv("O_Plan_Leads.csv", encoding='latin-1', low_memory=False)

Â  Â  Â  Â  # ================== 2ï¸âƒ£ DATA CLEANING & PREP (WITHOUT DEDUP) ==================
Â  Â  Â  Â Â 
Â  Â  Â  Â  # --- Date & Time Conversion ---
Â  Â  Â  Â  # Ù†Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®ØŒ Ù„ÙƒÙ† Ù„Ø§ Ù†Ø³ØªØ®Ø¯Ù…Ù‡Ø§ Ù„Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
Â  Â  Â  Â  dr['Modified Time'] = pd.to_datetime(dr['Modified Time'], errors='coerce', dayfirst=True)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Rename and Convert Date of Sale in OPLAN
Â  Â  Â  Â  if 'Date of Sale' in oplan.columns:
Â  Â  Â  Â  Â  Â  oplan.rename(columns={'Date of Sale': 'Sale Date'}, inplace=True)
Â  Â  Â  Â  Â  Â  oplan['Sale Date'] = pd.to_datetime(oplan['Sale Date'], errors='coerce', dayfirst=True)
Â  Â  Â  Â Â 
Â  Â  Â  Â  date_cols_dr = ["Completion Date", "Assigned date", "Approval date", "Denial Date", "Upload Date"]
Â  Â  Â  Â  for col in date_cols_dr:
Â  Â  Â  Â  Â  Â  if col in dr.columns:
Â  Â  Â  Â  Â  Â  Â  Â  dr[col] = pd.to_datetime(dr[col], errors='coerce', dayfirst=True)

Â  Â  Â  Â  # --- MCN Standardization and Handling Missing MCNs ---
Â  Â  Â  Â  for df_data in [dr, oplan]:
Â  Â  Â  Â  Â  Â  if 'MCN' in df_data.columns:
Â  Â  Â  Â  Â  Â  Â  Â  df_data['MCN'] = df_data['MCN'].astype(str).str.strip().replace({'nan': np.nan, '': np.nan})
Â  Â  Â  Â  Â  Â  Â  Â  # Ù„Ø§ ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø¹Ù…Ù„ ØªØ­Ù„ÙŠÙ„ ÙØ¹Ø§Ù„ Ø¨Ø¯ÙˆÙ† MCNØŒ Ù„Ø°Ø§ Ù†Ø­Ø°Ù Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù†Ø§Ù‚ØµØ© ÙÙŠ MCN ÙÙ‚Ø·
Â  Â  Â  Â  Â  Â  Â  Â  df_data.dropna(subset=['MCN'], inplace=True)Â 

Â  Â  Â  Â  # ğŸ”´ ØªÙ… Ø­Ø°Ù Ù…Ù†Ø·Ù‚ drop_duplicates Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ù…Ù† DR Ùˆ OPLAN

Â  Â  Â  Â  # --- Column Standardization ---
Â  Â  Â  Â  if 'Closer Name' in oplan.columns:
Â  Â  Â  Â  Â  Â  oplan['Closer Name'] = oplan['Closer Name'].fillna('N/A - Closer')
Â  Â  Â  Â Â 
Â  Â  Â  Â  if 'Chasing Disposition' in dr.columns:
Â  Â  Â  Â  Â  Â  dr['Chasing Disposition'] = dr['Chasing Disposition'].fillna('N/A - Disposition')

Â  Â  Â  Â  if 'Opener Status' in oplan.columns:
Â  Â  Â  Â  Â  Â  oplan['Opener Status'] = oplan['Opener Status'].fillna('N/A - Status Missing')
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Clean 'Assigned To' (Opener Name)
Â  Â  Â  Â  if 'Assigned To' in oplan.columns:
Â  Â  Â  Â  Â  Â  oplan['Assigned To'] = oplan['Assigned To'].fillna('N/A - Assigned Missing')
Â  Â  Â  Â  Â  Â  oplan['Assigned To'] = oplan['Assigned To'].str.replace('.', ' ', regex=False).str.title()


Â  Â  Â  Â  # Standardize Client column using Dr Chase version
Â  Â  Â  Â  if 'Client' in dr.columns:
Â  Â  Â  Â  Â  Â  dr['Client'] = dr['Client'].fillna('N/A - Client Missing')
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Drop redundant columns before merging
Â  Â  Â  Â  if 'Client' in oplan.columns:
Â  Â  Â  Â  Â  Â  oplan.drop(columns=['Client'], inplace=True, errors='ignore')
Â  Â  Â  Â  if 'Products' in dr.columns:
Â  Â  Â  Â  Â  Â  dr.drop(columns=['Products'], inplace=True, errors='ignore')


Â  Â  Â  Â  # --- Selecting Columns for Merge ---
Â  Â  Â  Â  # ğŸ”´ Ù…Ù„Ø§Ø­Ø¸Ø©: Ø§Ù„Ø¢Ù†ØŒ Dr Chase Ù‚Ø¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØªÙƒØ±Ø§Ø±Ø§Øª Ù„Ù†ÙØ³ Ø§Ù„Ù€ MCN.
Â  Â  Â  Â  # Ù‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù† ÙƒÙ„ ØµÙ Ù…Ù† OPLAN Ù‚Ø¯ ÙŠØªØ·Ø§Ø¨Ù‚ Ù…Ø¹ Ø¹Ø¯Ø© ØµÙÙˆÙ Ù…Ù† DR CHASE.
Â  Â  Â  Â  dr_cols = ['MCN', 'Dr Chase Lead Number', 'Chasing Disposition', 'Approval date', 'Denial Date', 'Client', 'Completion Date', 'Upload Date']
Â  Â  Â  Â  oplan_date_col = 'Sale Date' if 'Sale Date' in oplan.columns else 'Date of Sale'
Â  Â  Â  Â Â 
Â  Â  Â  Â  oplan_cols = ['MCN', 'O Plan Lead Number', 'Closer Name', 'Team Leader', 'Products', oplan_date_col, 'Opener Status', 'Assigned To']

Â  Â  Â  Â  # ================== 3ï¸âƒ£ CORE MERGE OPERATION (Allowing Duplicates) ==================
Â  Â  Â  Â  # Ù†Ø³ØªØ®Ø¯Ù… how='left' Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø³Ø¬Ù„Ø§Øª OPLAN ÙˆÙ…Ø·Ø§Ø¨Ù‚ØªÙ‡Ø§ Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø³Ø¬Ù„Ø§Øª DR CHASE Ø§Ù„ØªÙŠ ØªØ­Ù…Ù„ Ù†ÙØ³ MCN.
Â  Â  Â  Â  merged_df = pd.merge(
Â  Â  Â  Â  Â  Â  oplan[oplan_cols],
Â  Â  Â  Â  Â  Â  dr[dr_cols],
Â  Â  Â  Â  Â  Â  on='MCN',
Â  Â  Â  Â  Â  Â  how='left',
Â  Â  Â  Â  Â  Â  suffixes=('_OPLAN', '_DRCHASE')
Â  Â  Â  Â  )

Â  Â  Â  Â  # Fill NaN Chasing Disposition for leads not found in Dr Chase
Â  Â  Â  Â  merged_df['Chasing Disposition'] = merged_df['Chasing Disposition'].fillna('No Chase Data (OPlan Only)')

Â  Â  Â  Â  # ğŸ”´ ØªÙ… Ø­Ø°Ù drop_duplicates Ù…Ù† Ù‡Ù†Ø§ Ø£ÙŠØ¶Ù‹Ø§. Ø§Ù„Ø¢Ù† merged_df ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù†Ø§ØªØ¬Ø© Ø¹Ù† Ø§Ù„Ù€ Merge.
Â  Â  Â  Â Â 
Â  Â  Â  Â  # ğŸ”´ ØªØµØ­ÙŠØ­: ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙ†Ø§ Ø¥Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ù„Ù„Ø³Ø¬Ù„Ø§Øª ÙÙŠ Ù…Ù„ÙØ§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
Â  Â  Â  Â  total_oplan_rows = len(oplan)
Â  Â  Â  Â  total_dr_rows = len(dr)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Ù†Ø³ØªØ®Ø¯Ù… merged_df ÙƒÙ…Ø§ Ù‡Ùˆ Ù„Ø¹Ù…Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù†Ø§ØªØ¬Ø©.
Â  Â  Â  Â  return merged_df, dr, oplan, total_oplan_rows, total_dr_rows
Â  Â  Â  Â Â 
Â  Â  except Exception as e:
Â  Â  Â  Â  st.error(f"Failed to load data files or process: {e}")
Â  Â  Â  Â  return pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), 0, 0Â 

# ğŸ”´ ØªØ­Ø¯ÙŠØ«: Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø§Ù„Ù†Ø§ØªØ¬Ø© Ù…Ù† Ø§Ù„Ø¯Ø§Ù„Ø©
merged_df, dr_df, oplan_df, total_oplan_rows, total_dr_rows = load_and_merge_data()

# ================== 4ï¸âƒ£ DASHBOARD LAYOUT & TITLE ==================
st.title("ğŸ“Š Closer Performance Analysis")
st.markdown("---")

# Check if data loaded successfully
if merged_df.empty:
Â  Â  st.warning("Failed to load or merge data. Please check file names and paths.")
Â  Â  st.stop()

# ğŸ”´ NEW: Add custom CSS for general font improvements (larger base font, better legibility)
st.markdown(
Â  Â  """
Â  Â  <style>
Â  Â  /* Global font size increase for better visibility */
Â  Â  html, body {
Â  Â  Â  Â  font-size: 16px;Â 
Â  Â  }
Â  Â  /* Improve main headers (st.title) */
Â  Â  .stApp header {
Â  Â  Â  Â  font-size: 2.5rem;
Â  Â  }
Â  Â  /* Custom style for subheaders (st.subheader) - making them bolder/larger */
Â  Â  h2 {
Â  Â  Â  Â  font-size: 1.8rem;
Â  Â  Â  Â  font-weight: 600;
Â  Â  }
Â  Â  /* Ensure KPI labels (small text) are legible */
Â  Â  div[data-testid="stMetricLabel"] > div {
Â  Â  Â  Â  font-size: 1.1rem;
Â  Â  Â  Â  font-weight: 500;
Â  Â  }
Â  Â  /* Ensure KPI values (big numbers) are prominent */
Â  Â  div[data-testid="stMetricValue"] {
Â  Â  Â  Â  font-size: 2.5rem; /* Large KPI value size */
Â  Â  Â  Â  font-weight: bold;
Â  Â  }
Â  Â  /* Chart title improvement (Plotly) - handled in Plotly layout below */

Â  Â  </style>
Â  Â  """, unsafe_allow_html=True
)

# ================== 5ï¸âƒ£ SIDEBAR FILTERS (IMPROVED COMPACTNESS) ==================
with st.sidebar:
Â  Â  st.header("âš™ï¸ Data Filters")
Â  Â Â 
Â  Â  # 1. Closer Name Filter
Â  Â  closer_options = sorted(merged_df['Closer Name'].unique())
Â  Â Â 
Â  Â  target_closers = ['Aila Patrick', 'Lisa Hanz', 'Athina Henderson', 'Jordan Williams', 'Lauren Bailey', 'Linda Anderson', 'Maeve White', 'Raven Miller', 'Summer Hudson', 'Marcelle David', 'Lily Williams']
Â  Â Â 
Â  Â  default_closers = [c for c in target_closers if c in closer_options]
Â  Â  if not default_closers and closer_options:
Â  Â  Â  Â  default_closers = closer_options[:5]Â 
Â  Â  Â  Â Â 
Â  Â Â 
Â  Â  # --- Filter Action Buttons (Closer) ---
Â  Â  col_closer_btn1, col_closer_btn2 = st.columns(2)
Â  Â Â 
Â  Â  # Function to select the default closers
Â  Â  def select_default_closers():
Â  Â  Â  Â  st.session_state['selected_closers_state'] = default_closers
Â  Â  Â  Â Â 
Â  Â  # Function to clear all closers
Â  Â  def clear_all_closers():
Â  Â  Â  Â  st.session_state['selected_closers_state'] = []

Â  Â  # Initialize session state with the defined default list
Â  Â  if 'selected_closers_state' not in st.session_state:
Â  Â  Â  Â  st.session_state['selected_closers_state'] = default_closers
Â  Â  Â  Â Â 
Â  Â  def update_closer_selection():
Â  Â  Â  Â  pass

Â  Â Â 
Â  Â  # Buttons for fast action
Â  Â  with col_closer_btn1:
Â  Â  Â  Â  st.button("Select Default", on_click=select_default_closers, use_container_width=True)
Â  Â  with col_closer_btn2:
Â  Â  Â  Â  st.button("Clear All", on_click=clear_all_closers, use_container_width=True)
Â  Â Â 
Â  Â  # --- Filter for Sidebar ---
Â  Â  selected_closers_sidebar = st.multiselect(
Â  Â  Â  Â  "ğŸ§‘â€ğŸ’¼ Closer Name",
Â  Â  Â  Â  options=closer_options,
Â  Â  Â  Â  default=st.session_state['selected_closers_state'],
Â  Â  Â  Â  key='selected_closers_state',
Â  Â  Â  Â  on_change=update_closer_selection
Â  Â  )
Â  Â Â 
Â  Â  # Use expander for primary secondary filters
Â  Â  with st.expander("â¬‡ï¸ Advanced Filters: Disposition & Opener", expanded=False):
Â  Â  Â  Â Â 
Â  Â  Â  Â  # 2. Chasing Disposition Filter
Â  Â  Â  Â  disposition_options = sorted(merged_df['Chasing Disposition'].unique())
Â  Â  Â  Â Â 
Â  Â  Â  Â  # TWEAK: Exclude 'No Chase Data (OPlan Only)' from default selection
Â  Â  Â  Â  default_dispositions = [disp for disp in disposition_options if disp != 'No Chase Data (OPlan Only)']
Â  Â  Â  Â  selected_dispositions = st.multiselect(
Â  Â  Â  Â  Â  Â  "ğŸ·ï¸ Chasing Disposition",Â 
Â  Â  Â  Â  Â  Â  options=disposition_options,
Â  Â  Â  Â  Â  Â  default=default_dispositions
Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  Â  Â  # 3. Opener Status Filter
Â  Â  Â  Â  opener_options = sorted(merged_df['Opener Status'].unique())
Â  Â  Â  Â  selected_openers = st.multiselect(
Â  Â  Â  Â  Â  Â  "ğŸš€ Opener Status",Â 
Â  Â  Â  Â  Â  Â  options=opener_options,
Â  Â  Â  Â  Â  Â  default=opener_options
Â  Â  Â  Â  )
Â  Â Â 
Â  Â  Â  Â  # 4. Client Filter
Â  Â  Â  Â  merged_df['Client'] = merged_df['Client'].astype(str)
Â  Â  Â  Â  client_options = sorted(merged_df['Client'].unique())
Â  Â  Â  Â  selected_clients = st.multiselect(
Â  Â  Â  Â  Â  Â  "ğŸ’¼ Client",Â 
Â  Â  Â  Â  Â  Â  options=client_options,
Â  Â  Â  Â  Â  Â  default=client_options
Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  # Assigned To filter
Â  Â  assigned_to_options = sorted(merged_df['Assigned To'].unique())

Â  Â  # --- Assigned To Action Buttons ---
Â  Â  # Initialize state for Assigned To filter
Â  Â  if 'selected_assigned_to_state' not in st.session_state:
Â  Â  Â  Â  st.session_state['selected_assigned_to_state'] = assigned_to_options

Â  Â  def select_all_assigned_to():
Â  Â  Â  Â  st.session_state['selected_assigned_to_state'] = assigned_to_options
Â  Â Â 
Â  Â  def clear_all_assigned_to():
Â  Â  Â  Â  st.session_state['selected_assigned_to_state'] = []

Â  Â  with st.expander("ğŸ™‹â€â™‚ï¸ Filter by Assigned To (Opener)", expanded=False):
Â  Â  Â  Â  col_op_btn1, col_op_btn2 = st.columns(2)
Â  Â  Â  Â  with col_op_btn1:
Â  Â  Â  Â  Â  Â  st.button("Select All", key="op_select_all", on_click=select_all_assigned_to, use_container_width=True)
Â  Â  Â  Â  with col_op_btn2:
Â  Â  Â  Â  Â  Â  st.button("Clear All", key="op_clear_all", on_click=clear_all_assigned_to, use_container_width=True)

Â  Â  Â  Â  selected_assigned_to = st.multiselect(
Â  Â  Â  Â  Â  Â  "Select Opener(s)", # Simplified label inside the expander
Â  Â  Â  Â  Â  Â  options=assigned_to_options,
Â  Â  Â  Â  Â  Â  default=st.session_state['selected_assigned_to_state'],
Â  Â  Â  Â  Â  Â  key='selected_assigned_to_state'
Â  Â  Â  Â  )


Â  Â  st.markdown("---")
Â  Â  st.subheader("ğŸ“š Dataset Information")
Â  Â  # ğŸ”´ ØªØ­Ø¯ÙŠØ«: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø§Ù„ØªÙŠ ØªØ­Ù…Ù„ Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ø£ØµÙ„ÙŠØ©
Â  Â  st.metric("Total OPlan Records (Initial)", f"{total_oplan_rows:,}")
Â  Â  st.metric("Total Dr Chase Records (Initial)", f"{total_dr_rows:,}")
Â  Â  st.metric("Total Merged Records (All Matches)", f"{len(merged_df):,}")


# ================== 6ï¸âƒ£ APPLY FILTERS ==================
active_closers = selected_closers_sidebar


filtered_df = merged_df.copy()

# Apply the active closer filter
if active_closers:
Â  Â  filtered_df = filtered_df[filtered_df['Closer Name'].isin(active_closers)]

# Apply other filters
if selected_assigned_to:
Â  Â  filtered_df = filtered_df[filtered_df['Assigned To'].isin(selected_assigned_to)]

if selected_dispositions:
Â  Â  filtered_df = filtered_df[filtered_df['Chasing Disposition'].isin(selected_dispositions)]
Â  Â Â 
if selected_openers:
Â  Â  filtered_df = filtered_df[filtered_df['Opener Status'].isin(selected_openers)]

if selected_clients:
Â  Â  filtered_df = filtered_df[filtered_df['Client'].isin(selected_clients)]


# Recalculate leads count after filtering
total_filtered_leads = len(filtered_df)

# ================== 7ï¸âƒ£ KPIs (Key Metrics) ==================
st.subheader("Key Performance Indicators (KPIs)")

# Metrics derived from the MERGED (OPlan/Dr Chase) data
total_leads = len(merged_df)
leads_after_filter = len(filtered_df)
# leads_chased: Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…ÙÙ„ØªØ±Ø© Ø§Ù„ØªÙŠ Ù„Ù‡Ø§ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ§Ø¨Ø¹Ø© ÙÙŠ Dr Chase
leads_chased = filtered_df[filtered_df['Chasing Disposition'] != 'No Chase Data (OPlan Only)'].shape[0]

# --- KPI CALCULATION ---
# ğŸ”´ Ù…Ù„Ø§Ø­Ø¸Ø©: Ø¨Ù…Ø§ Ø£Ù†Ù†Ø§ Ù„Ù… Ù†Ù‚Ù… Ø¨Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§ØªØŒ ÙØ¥Ù† Ø­Ø³Ø§Ø¨ KPIs Ø§Ù„Ø¢Ù† ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª ÙˆÙ„ÙŠØ³ Ø¹Ø¯Ø¯ Ø§Ù„Ù€ MCNs Ø§Ù„ÙØ±ÙŠØ¯Ø©.
# Ù†Ø­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„Ù€ MCNs Ø§Ù„ÙØ±ÙŠØ¯Ø© ÙÙŠ DR CHASE Ø«Ù… Ù…Ø·Ø§Ø¨Ù‚ØªÙ‡Ø§ Ù…Ø¹ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…ÙÙ„ØªØ±Ø© ÙÙŠ merged_df
if all(col in dr_df.columns for col in ['Completion Date', 'Upload Date', 'Approval date', 'Denial Date']):
Â  Â Â 
Â  Â  # Ù†Ø­Ø¯Ø¯ Ø§Ù„Ù€ MCNs Ø§Ù„ÙØ±ÙŠØ¯Ø© Ø§Ù„ØªÙŠ Ø­Ù‚Ù‚Øª Ø­Ø§Ù„Ø© Ù…Ø¹ÙŠÙ†Ø© ÙÙŠ DR CHASE
Â  Â  completed_mcns = dr_df.dropna(subset=['Completion Date'])['MCN'].unique()
Â  Â  uploaded_mcns = dr_df.dropna(subset=['Upload Date'])['MCN'].unique()
Â  Â  approved_mcns = dr_df.dropna(subset=['Approval date'])['MCN'].unique()
Â  Â  denied_mcns = dr_df.dropna(subset=['Denial Date'])['MCN'].unique()
Â  Â Â 
Â  Â  # Ø«Ù… Ù†Ø­Ø³Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª ÙÙŠ filtered_df Ø§Ù„ØªÙŠ ØªØªØ·Ø§Ø¨Ù‚ Ù…Ø¹ Ù‡Ø°Ù‡ Ø§Ù„Ù€ MCNs
Â  Â  # Ø¨Ù…Ø§ Ø£Ù†Ù†Ø§ Ù„Ù… Ù†Ø­Ø°Ù Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª ÙÙŠ filtered_dfØŒ ÙØ¥Ù† Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø© Ø³ØªØ­Ø³Ø¨ Ø£ÙƒØ«Ø± Ù…Ù† Ù…Ø±Ø© Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ù‡Ø§ MCN Ù…Ø·Ø§Ø¨Ù‚
Â  Â  filtered_completed = filtered_df[filtered_df['MCN'].isin(completed_mcns)].shape[0]
Â  Â  filtered_uploaded = filtered_df[filtered_df['MCN'].isin(uploaded_mcns)].shape[0]
Â  Â  filtered_approved = filtered_df[filtered_df['MCN'].isin(approved_mcns)].shape[0]
Â  Â  filtered_denied = filtered_df[filtered_df['MCN'].isin(denied_mcns)].shape[0]
else:
Â  Â  filtered_completed = 0
Â  Â  filtered_uploaded = 0
Â  Â  filtered_approved = 0
Â  Â  filtered_denied = 0

# Calculate percentages (based on chased leads for status KPIs)
pct_chased = (leads_chased / leads_after_filter * 100) if leads_after_filter > 0 else 0
# ğŸ”´ Ù…Ù„Ø§Ø­Ø¸Ø©: Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù‡Ø¯Ù Ù‡Ùˆ Ù†Ø³Ø¨Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ø³Ø¬Ù„ Ù…Ù† Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªÙŠ ØªÙ… ØªØªØ¨Ø¹Ù‡Ø§
pct_completed = (filtered_completed / leads_chased * 100) if leads_chased > 0 else 0
pct_uploaded = (filtered_uploaded / leads_chased * 100) if leads_chased > 0 else 0
pct_approved = (filtered_approved / leads_chased * 100) if leads_chased > 0 else 0
pct_denied = (filtered_denied / leads_chased * 100) if leads_chased > 0 else 0

# --- KPI DISPLAY (6 columns) ---
col1, col2, col5, col6, col3, col4 = st.columns(6)

col1.metric("Total Filtered Records", f"{leads_after_filter:,}", f"out of {total_leads:,}")
col2.metric("Records Chased", f"{leads_chased:,}", f"{pct_chased:.1f}% of Filtered")

col5.metric("Approvals", f"{filtered_approved:,}", f"{pct_approved:.1f}% of Chased")
col6.metric("Denials", f"{filtered_denied:,}", f"{pct_denied:.1f}% of Chased")

col3.metric("Completed", f"{filtered_completed:,}", f"{pct_completed:.1f}% of Chased")
col4.metric("Uploaded", f"{filtered_uploaded:,}", f"{pct_uploaded:.1f}% of Chased")


# Apply custom styling to the metric cards
style_metric_cards(
Â  Â  background_color="#121270",
Â  Â  border_left_color="#f20045",
Â  Â  box_shadow="3px 3px 10px rgba(0,0,0,0.3)"
)
st.markdown("---")

# ================== 8ï¸âƒ£ CHARTS: Closer vs Disposition (THE CORE ANALYSIS) ==================

PLOTLY_FONT_SIZE = 14

st.subheader("Distribution Analysis")

# Row 1: Closer and Disposition Counts (Side-by-side)
col_chart_1, col_chart_2 = st.columns(2)

# --- Chart 1: Closer Name Count ---
with col_chart_1:
Â  Â  closer_count = filtered_df['Closer Name'].value_counts().reset_index()
Â  Â  closer_count.columns = ["Closer Name", "Count"]
Â  Â Â 
Â  Â  if not closer_count.empty:
Â  Â  Â  Â  fig1 = px.bar(
Â  Â  Â  Â  Â  Â  closer_count,Â 
Â  Â  Â  Â  Â  Â  x="Closer Name",Â 
Â  Â  Â  Â  Â  Â  y="Count",Â 
Â  Â  Â  Â  Â  Â  title="Total Leads by Closer Name (All Records)",Â # ğŸ”´ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
Â  Â  Â  Â  Â  Â  text_auto=True,
Â  Â  Â  Â  Â  Â  template='plotly_white',
Â  Â  Â  Â  Â  Â  color='Closer Name',
Â  Â  Â  Â  Â  Â  color_discrete_sequence=px.colors.qualitative.Pastel
Â  Â  Â  Â  )
Â  Â  Â  Â  fig1.update_layout(
Â  Â  Â  Â  Â  Â  font=dict(size=PLOTLY_FONT_SIZE),
Â  Â  Â  Â  Â  Â  title_font=dict(size=PLOTLY_FONT_SIZE + 4)
Â  Â  Â  Â  )
Â  Â  Â  Â  fig1.update_xaxes(categoryorder='total descending', tickfont=dict(size=PLOTLY_FONT_SIZE))
Â  Â  Â  Â  fig1.update_yaxes(tickfont=dict(size=PLOTLY_FONT_SIZE))
Â  Â  Â  Â  st.plotly_chart(fig1, use_container_width=True)
Â  Â  else:
Â  Â  Â  Â  st.info("No data available to display Closer Name Count based on current filters.")
Â  Â Â 

# --- Chart 2: Chasing Disposition Count ---
with col_chart_2:
Â  Â  disposition_count = filtered_df['Chasing Disposition'].value_counts().reset_index()
Â  Â  disposition_count.columns = ["Chasing Disposition", "Count"]
Â  Â Â 
Â  Â  if not disposition_count.empty:
Â  Â  Â  Â  fig2 = px.bar(
Â  Â  Â  Â  Â  Â  disposition_count,Â 
Â  Â  Â  Â  Â  Â  x="Chasing Disposition",Â 
Â  Â  Â  Â  Â  Â  y="Count",Â 
Â  Â  Â  Â  Â  Â  title="Distribution of Chasing Dispositions (Count)",Â 
Â  Â  Â  Â  Â  Â  text_auto=True,
Â  Â  Â  Â  Â  Â  template='plotly_white',
Â  Â  Â  Â  Â  Â  color='Chasing Disposition',
Â  Â  Â  Â  Â  Â  color_discrete_sequence=px.colors.qualitative.Pastel
Â  Â  Â  Â  )
Â  Â  Â  Â  fig2.update_layout(
Â  Â  Â  Â  Â  Â  font=dict(size=PLOTLY_FONT_SIZE),
Â  Â  Â  Â  Â  Â  title_font=dict(size=PLOTLY_FONT_SIZE + 4)
Â  Â  Â  Â  )
Â  Â  Â  Â  fig2.update_xaxes(categoryorder='total descending', tickfont=dict(size=PLOTLY_FONT_SIZE))
Â  Â  Â  Â  fig2.update_yaxes(tickfont=dict(size=PLOTLY_FONT_SIZE))
Â  Â  Â  Â  st.plotly_chart(fig2, use_container_width=True)
Â  Â  else:
Â  Â  Â  Â  st.info("No data available to display Chasing Disposition Count based on current filters.")


# --- Chart 3: Closer -> Disposition Treemap (FULL WIDTH) ---
st.markdown("### Closer Performance Breakdown")
treemap_data = filtered_df.dropna(subset=['Closer Name', 'Chasing Disposition']).copy()
if not treemap_data.empty:
Â  Â  fig3 = px.treemap(
Â  Â  Â  Â  treemap_data,
Â  Â  Â  Â  path=[px.Constant("All Closers"), 'Closer Name', 'Chasing Disposition'],
Â  Â  Â  Â  title="Closer Performance Breakdown by Chasing Disposition (Treemap)",
Â  Â  Â  Â  template='plotly_white',
Â  Â  Â  Â  color='Chasing Disposition',
Â  Â  Â  Â  color_discrete_sequence=px.colors.qualitative.Pastel
Â  Â  )
Â  Â  fig3.update_layout(
Â  Â  Â  Â  margin = dict(t=50, l=25, r=25, b=25),
Â  Â  Â  Â  font=dict(size=PLOTLY_FONT_SIZE + 2),
Â  Â  Â  Â  title_font=dict(size=PLOTLY_FONT_SIZE + 4)
Â  Â  )
Â  Â  st.plotly_chart(fig3, use_container_width=True)
else:
Â  Â  st.warning("No data available to display the Treemap based on current filters.")


# --- Chart 4: Client Distribution (FULL WIDTH) ---
st.markdown("### Client Distribution Analysis")
client_count = filtered_df['Client'].value_counts().reset_index()
client_count.columns = ["Client", "Count"]

if not client_count.empty:
Â  Â  fig4 = px.bar(
Â  Â  Â  Â  client_count,Â 
Â  Â  Â  Â  x="Client",Â 
Â  Â  Â  Â  y="Count",Â 
Â  Â  Â  Â  title="Distribution of Leads by Client (From Dr Chase)",Â 
Â  Â  Â  Â  text_auto=True,
Â  Â  Â  Â  template='plotly_white',
Â  Â  Â  Â  color='Client',
Â  Â  Â  Â  color_discrete_sequence=px.colors.qualitative.Pastel
Â  Â  )
Â  Â  fig4.update_layout(
Â  Â  Â  Â  font=dict(size=PLOTLY_FONT_SIZE),
Â  Â  Â  Â  title_font=dict(size=PLOTLY_FONT_SIZE + 4)
Â  Â  )
Â  Â  fig4.update_xaxes(categoryorder='total descending', tickfont=dict(size=PLOTLY_FONT_SIZE))
Â  Â  fig4.update_yaxes(tickfont=dict(size=PLOTLY_FONT_SIZE))
Â  Â  st.plotly_chart(fig4, use_container_width=True)
else:
Â  Â  st.warning("No data available to display Client Distribution based on current filters.")


# --- Chart 5: Opener Status Count (Full Width) ---
st.subheader("Opener Status Distribution")
opener_count = filtered_df['Opener Status'].value_counts().reset_index()
opener_count.columns = ["Opener Status", "Count"]

if not opener_count.empty:
Â  Â  fig5 = px.bar(
Â  Â  Â  Â  opener_count,Â 
Â  Â  Â  Â  x="Opener Status",Â 
Â  Â  Â  Â  y="Count",Â 
Â  Â  Â  Â  title="Leads by Opener Status (Count)",Â 
Â  Â  Â  Â  text_auto=True,
Â  Â  Â  Â  template='plotly_white',
Â  Â  Â  Â  color='Opener Status',
Â  Â  Â  Â  color_discrete_sequence=px.colors.qualitative.Pastel
Â  Â  )
Â  Â  fig5.update_layout(
Â  Â  Â  Â  font=dict(size=PLOTLY_FONT_SIZE),
Â  Â  Â  Â  title_font=dict(size=PLOTLY_FONT_SIZE + 4)
Â  Â  )
Â  Â  fig5.update_xaxes(categoryorder='total descending', tickfont=dict(size=PLOTLY_FONT_SIZE))
Â  Â  fig5.update_yaxes(tickfont=dict(size=PLOTLY_FONT_SIZE))
Â  Â  st.plotly_chart(fig5, use_container_width=True)
else:
Â  Â  st.info("No data available to display Opener Status Distribution based on current filters.")

st.markdown("---")

# ================== 9ï¸âƒ£ DATA TABLE PREVIEW ==================
st.subheader("ğŸ“‹ Merged and Filtered Data Preview")
# FINAL FIX: Using the simplified list of columns
data_preview_cols = ['MCN', 'Closer Name', 'Opener Status', 'Chasing Disposition', 'Products',Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â 'Approval date', 'Denial Date', 'Client', 'Assigned To']

if not filtered_df.empty:
Â  Â  st.dataframe(filtered_df[data_preview_cols], use_container_width=True)
else:
Â  Â  st.info("The filtered data table is empty.")
